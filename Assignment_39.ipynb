{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
        "application.\n",
        "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
        "Provide an example to illustrate its application.\n",
        "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
        "example to illustrate its application.\n",
        "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
        "Extraction? Provide an example to illustrate this concept.\n",
        "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
        "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
        "preprocess the data.\n",
        "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
        "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
        "dimensionality of the dataset.\n",
        "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
        "values to a range of -1 to 1.\n",
        "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
        "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
      ],
      "metadata": {
        "id": "Ypn44iukz760"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1:**  \n",
        "Min-Max scaling is a normalization technique that transforms features to a specific range, usually [0,1] or [-1,1]. It is done using the formula:  \n",
        "\\[\n",
        "X' = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}} \\times (new_{\\text{max}} - new_{\\text{min}}) + new_{\\text{min}}\n",
        "\\]  \n",
        "For example, if we scale the values [10, 20, 30] to a range of [0,1], the transformed values will be [0, 0.5, 1]. This ensures all features have the same scale, improving model convergence in ML algorithms.  \n",
        "\n",
        "**Q2:**  \n",
        "The Unit Vector technique, also called vector normalization, scales data so that each sample has a unit norm, meaning its magnitude is 1. Unlike Min-Max scaling, which rescales values within a fixed range, Unit Vector scaling focuses on direction rather than absolute values.  \n",
        "For example, if a data point is [3, 4], its unit vector is calculated as:  \n",
        "\\[\n",
        "\\left(\\frac{3}{\\sqrt{3^2 + 4^2}}, \\frac{4}{\\sqrt{3^2 + 4^2}}\\right) = (0.6, 0.8)\n",
        "\\]  \n",
        "This is useful in text processing and cosine similarity calculations.  \n",
        "\n",
        "**Q3:**  \n",
        "Principal Component Analysis (PCA) is a dimensionality reduction technique that transforms correlated features into a smaller set of uncorrelated components while preserving the most variance. It works by computing eigenvectors and eigenvalues of the covariance matrix.  \n",
        "For example, in a dataset with 100 features, PCA can reduce it to 10 principal components that retain most of the variance, improving model performance and reducing computation time.  \n",
        "\n",
        "**Q4:**  \n",
        "PCA is a feature extraction technique because it transforms the original features into new principal components that represent the most variance in the data. Instead of selecting a subset of features (as in feature selection), PCA generates new features.  \n",
        "For example, in image compression, a high-resolution image with many pixel values can be reduced to a lower-dimensional space while preserving essential features, enabling faster processing.  \n",
        "\n",
        "**Q5:**  \n",
        "For a food delivery recommendation system, Min-Max scaling can be applied to price, rating, and delivery time so they have comparable scales. Using a range of [0,1], delivery times (e.g., 10-50 minutes) and ratings (e.g., 1-5 stars) would be transformed proportionally, ensuring no feature dominates the model due to differing units.  \n",
        "\n",
        "**Q6:**  \n",
        "For stock price prediction, PCA can reduce high-dimensional financial and market trend data while preserving essential patterns. By applying PCA, correlated financial indicators (e.g., revenue, profit, expenses) can be transformed into fewer principal components that still capture most of the variance, improving model efficiency and reducing overfitting.  \n",
        "\n",
        "**Q7:**  \n",
        "Using Min-Max scaling to transform the values [1, 5, 10, 15, 20] to a range of [-1,1]:  \n",
        "\\[\n",
        "X' = \\frac{X - 1}{20 - 1} \\times (1 - (-1)) + (-1)\n",
        "\\]  \n",
        "The transformed values are: **[-1, -0.47, 0.05, 0.58, 1]**  \n",
        "\n",
        "**Q8:**  \n",
        "For the dataset [height, weight, age, gender, blood pressure], PCA can reduce dimensionality by selecting principal components that explain most variance. The number of components retained depends on explained variance (typically >95%). If height, weight, and age are highly correlated, they might be reduced to one component, while gender and blood pressure might be separate. Hence, around **2-3 principal components** may be sufficient."
      ],
      "metadata": {
        "id": "OhMGTbTp0K36"
      }
    }
  ]
}