{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. What is Lasso Regression, and how does it differ from other regression techniques?  \n",
        "Lasso Regression (Least Absolute Shrinkage and Selection Operator) is a linear regression technique that adds L1 regularization, which penalizes the absolute sum of coefficients. Unlike Ordinary Least Squares (OLS), Lasso can shrink some coefficients to zero, effectively selecting important features and reducing complexity. This differs from Ridge Regression, which applies L2 regularization and does not eliminate coefficients but only shrinks them.  \n",
        "\n",
        "### Q2. What is the main advantage of using Lasso Regression in feature selection?  \n",
        "The main advantage of Lasso Regression is its ability to perform automatic feature selection by shrinking some coefficients to zero. This helps in identifying the most relevant variables while reducing overfitting, making the model simpler and more interpretable.  \n",
        "\n",
        "### Q3. How do you interpret the coefficients of a Lasso Regression model?  \n",
        "In Lasso Regression, coefficients represent the effect of each predictor on the target variable. If a coefficient is zero, it means that the corresponding feature is not important for the prediction. Non-zero coefficients indicate the influence of selected features, though they are often smaller than in OLS due to regularization.  \n",
        "\n",
        "### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?  \n",
        "The main tuning parameter in Lasso Regression is the regularization parameter \\(\\lambda\\), which controls the strength of L1 penalty. A higher \\(\\lambda\\) increases sparsity by setting more coefficients to zero, improving feature selection but possibly underfitting. A lower \\(\\lambda\\) reduces regularization, allowing more features but increasing the risk of overfitting.  \n",
        "\n",
        "### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?  \n",
        "Yes, Lasso Regression can handle non-linear problems when combined with polynomial or basis function transformations. By applying polynomial features or kernel methods before fitting the model, Lasso can capture non-linear relationships while still performing feature selection and regularization.  \n",
        "\n",
        "### Q6. What is the difference between Ridge Regression and Lasso Regression?  \n",
        "The key difference is in the regularization term: Ridge Regression uses L2 regularization, which shrinks coefficients continuously but never sets them to zero, whereas Lasso Regression uses L1 regularization, which can shrink coefficients to exactly zero, leading to feature selection. Ridge is preferred when all features contribute, while Lasso is useful when only a few important predictors exist.  \n",
        "\n",
        "### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?  \n",
        "Yes, Lasso Regression can handle multicollinearity by selecting only one among highly correlated features and setting others to zero. However, it may arbitrarily choose one variable over another, leading to potential instability. In contrast, Ridge Regression distributes the effect among correlated features.  \n",
        "\n",
        "### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?  \n",
        "The optimal \\(\\lambda\\) value is chosen using cross-validation techniques like k-fold cross-validation or grid search. The best \\(\\lambda\\) balances model complexity and performance, minimizing validation error while preventing overfitting or underfitting."
      ],
      "metadata": {
        "id": "P0JyXYadBDHk"
      }
    }
  ]
}