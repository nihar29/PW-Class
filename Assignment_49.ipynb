{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. What is Elastic Net Regression and how does it differ from other regression techniques?  \n",
        "Elastic Net Regression is a linear regression method that combines both L1 (Lasso) and L2 (Ridge) regularization. It overcomes Lasso’s limitation of selecting only one feature among highly correlated ones by distributing weights among them. Unlike Ridge, which only shrinks coefficients, Elastic Net can also perform feature selection like Lasso but in a more stable manner.  \n",
        "\n",
        "### Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?  \n",
        "The optimal values of the regularization parameters (\\(\\alpha\\) and \\(\\lambda\\)) are chosen using techniques like cross-validation, grid search, or randomized search. Typically, \\(\\alpha\\) controls the mix of L1 and L2 regularization, while \\(\\lambda\\) controls the overall strength of the penalty.  \n",
        "\n",
        "### Q3. What are the advantages and disadvantages of Elastic Net Regression?  \n",
        "**Advantages:** It handles multicollinearity better than Lasso, performs automatic feature selection, and balances bias-variance trade-off.  \n",
        "**Disadvantages:** It requires tuning two parameters, is computationally more expensive than Lasso or Ridge, and may still suffer from overfitting if \\(\\lambda\\) is not properly chosen.  \n",
        "\n",
        "### Q4. What are some common use cases for Elastic Net Regression?  \n",
        "Elastic Net is commonly used in high-dimensional datasets with correlated features, such as genomics, financial modeling, text classification, and image analysis. It is useful when there are more predictors than observations or when feature selection is important.  \n",
        "\n",
        "### Q5. How do you interpret the coefficients in Elastic Net Regression?  \n",
        "Coefficients indicate the importance of features in predicting the target variable. Non-zero coefficients suggest that a feature contributes to the model, while near-zero values indicate weak relevance. Since Elastic Net uses both L1 and L2 penalties, correlated features may share importance rather than eliminating one entirely.  \n",
        "\n",
        "### Q6. How do you handle missing values when using Elastic Net Regression?  \n",
        "Missing values should be handled before fitting the model using techniques like mean/median imputation, KNN imputation, or dropping missing data points. Scikit-learn’s `SimpleImputer` can be used to preprocess missing values before training an Elastic Net model.  \n",
        "\n",
        "### Q7. How do you use Elastic Net Regression for feature selection?  \n",
        "Elastic Net automatically selects important features by shrinking some coefficients to zero while keeping others. The regularization parameters can be tuned to control how many features are retained. Features with non-zero coefficients after training are considered significant for prediction.  \n",
        "\n",
        "### Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?  \n",
        "You can pickle a trained Elastic Net model using Python’s `pickle` module:  \n",
        "\n",
        "import pickle  \n",
        "with open('elastic_net_model.pkl', 'wb') as f:  \n",
        "    pickle.dump(model, f)\n",
        "\n",
        "To unpickle and load the model:  \n",
        "\n",
        "with open('elastic_net_model.pkl', 'rb') as f:  \n",
        "    model = pickle.load(f)  \n",
        "\n",
        "### Q9. What is the purpose of pickling a model in machine learning?  \n",
        "Pickling a model allows you to save and reload it later without retraining, making deployment easier. This is useful for sharing models, performing predictions on new data, or resuming work without losing previous computations."
      ],
      "metadata": {
        "id": "dk6BbhIUBmwc"
      }
    }
  ]
}