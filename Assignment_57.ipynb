{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Relationship Between Polynomial Functions and Kernel Functions in Machine Learning\n",
        "In Support Vector Machines (SVM), kernel functions help transform data into a higher-dimensional space where it can be separated linearly. A polynomial kernel is a type of kernel function that maps input features into a higher-degree polynomial space without explicitly computing the transformation. It is defined as:\n",
        "\n",
        "ùêæ\n",
        "(\n",
        "ùë•\n",
        "ùëñ\n",
        ",\n",
        "ùë•\n",
        "ùëó\n",
        ")\n",
        "=\n",
        "(\n",
        "ùë•\n",
        "ùëñ\n",
        "ùëá\n",
        "ùë•\n",
        "ùëó\n",
        "+\n",
        "ùëê\n",
        ")\n",
        "ùëë\n",
        "K(x\n",
        "i\n",
        "‚Äã\n",
        " ,x\n",
        "j\n",
        "‚Äã\n",
        " )=(x\n",
        "i\n",
        "T\n",
        "‚Äã\n",
        " x\n",
        "j\n",
        "‚Äã\n",
        " +c)\n",
        "d\n",
        "\n",
        "where:\n",
        "\n",
        "ùë•\n",
        "ùëñ\n",
        ",\n",
        "ùë•\n",
        "ùëó\n",
        "x\n",
        "i\n",
        "‚Äã\n",
        " ,x\n",
        "j\n",
        "‚Äã\n",
        "  are input feature vectors,\n",
        "ùëê\n",
        "c is a constant (controls influence of higher-order terms),\n",
        "ùëë\n",
        "d is the degree of the polynomial.\n",
        "This is useful when data is non-linearly separable but can be separated in a higher-dimensional space.\n",
        "\n",
        "Q2. Implementing SVM with a Polynomial Kernel in Python (Scikit-learn)"
      ],
      "metadata": {
        "id": "jo47Bu27Y1TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]  # Using first two features for visualization\n",
        "y = iris.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train SVM with Polynomial Kernel\n",
        "svm_poly = SVC(kernel=\"poly\", degree=3, C=1.0)\n",
        "svm_poly.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = svm_poly.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Polynomial SVM Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-1chcAmY2UG",
        "outputId": "3a4b9d5a-48ac-46cf-8b4d-489ed2869092"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial SVM Accuracy: 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Effect of Increasing Epsilon on Support Vectors in SVR\n",
        "In Support Vector Regression (SVR), epsilon (Œµ) defines a margin of tolerance where errors are ignored. Increasing Œµ results in:\n",
        "\n",
        "Fewer support vectors because more data points fall within the margin.\n",
        "A simpler model with less flexibility.\n",
        "Higher bias and lower variance, meaning the model generalizes more but may underfit.\n",
        "Conversely, decreasing Œµ results in more support vectors, making the model more flexible but potentially overfitting.\n",
        "\n",
        "Q4. Effect of Kernel, C, Epsilon, and Gamma on SVR Performance\n",
        "Parameter\tEffect\tWhen to Increase?\tWhen to Decrease?\n",
        "Kernel Function\tDefines feature transformation\tIf data is non-linearly related\tIf data is linearly related\n",
        "C (Regularization Parameter)\tControls trade-off between margin and misclassification\tIf you want fewer errors, but risk overfitting\tIf you want better generalization, but allow some misclassification\n",
        "Epsilon (Œµ)\tDefines margin of tolerance for error\tIf you want simpler models (fewer support vectors)\tIf you want higher precision (more support vectors)\n",
        "Gamma (Œ≥) in RBF Kernel\tControls influence of a single data point\tIf the dataset is complex (higher model complexity)\tIf the dataset is simple (reduce overfitting)\n",
        "Q5. Assignment: SVM Classifier with Hyperparameter Tuning\n",
        "Steps:\n",
        "Load a dataset of your choice.\n",
        "Split it into training and testing sets.\n",
        "Preprocess data (scaling/normalization).\n",
        "Train an SVC classifier on the training set.\n",
        "Make predictions on the test set.\n",
        "Evaluate performance using accuracy, precision, recall, and F1-score.\n",
        "Tune hyperparameters using GridSearchCV or RandomizedSearchCV.\n",
        "Retrain the model with the best parameters.\n",
        "Save the trained classifier for future use.\n",
        "### **Implementation using Breast Cancer Dataset**"
      ],
      "metadata": {
        "id": "kmT99p0qZAtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train initial SVC model\n",
        "svc = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\")\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "print(\"Initial Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 0.1, 1, 10],\n",
        "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Train tuned model\n",
        "best_svc = grid_search.best_estimator_\n",
        "best_svc.fit(X_train, y_train)\n",
        "\n",
        "# Final predictions\n",
        "y_pred_best = best_svc.predict(X_test)\n",
        "\n",
        "# Evaluate tuned model\n",
        "print(\"Tuned Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best):.2f}\")\n",
        "print(classification_report(y_test, y_pred_best))\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(best_svc, \"svm_classifier.pkl\")\n",
        "print(\"Trained model saved as 'svm_classifier.pkl'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BwdX9m-ZBh4",
        "outputId": "4a9bfee8-3fea-4660-c001-9b5114a6d7a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Model Performance:\n",
            "Accuracy: 0.98\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98        43\n",
            "           1       0.97      1.00      0.99        71\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Tuned Model Performance:\n",
            "Accuracy: 0.98\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98        43\n",
            "           1       0.97      1.00      0.99        71\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n",
            "Trained model saved as 'svm_classifier.pkl'\n"
          ]
        }
      ]
    }
  ]
}