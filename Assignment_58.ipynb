{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Q1. Best Regression Metric for Predicting House Prices with SVM Regression**  \n",
        "For house price prediction, **Mean Absolute Error (MAE)** is often the best metric because:  \n",
        "- It provides an interpretable error in the same unit as house prices.  \n",
        "- It is **robust to outliers**, unlike MSE, which squares large errors.  \n",
        "- It gives a direct estimate of the average error in price prediction.  \n",
        "\n",
        "However, **Root Mean Squared Error (RMSE)** is also useful if we want to penalize large errors more.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q2. Choosing Between MSE and R-squared for House Price Prediction**  \n",
        "If the goal is to predict actual house prices **as accurately as possible**, then **Mean Squared Error (MSE) or RMSE** is better than R-squared because:  \n",
        "- MSE provides an absolute measure of error in house price units.  \n",
        "- R-squared only explains variance but does not indicate prediction accuracy.  \n",
        "- RMSE is better than MSE since it maintains the same unit as house prices.  \n",
        "\n",
        "Thus, **RMSE is the best choice** for precise price prediction.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q3. Best Regression Metric for a Dataset with Many Outliers**  \n",
        "When dealing with **outliers**, **Mean Absolute Error (MAE)** is the best metric because:  \n",
        "- Unlike MSE/RMSE, it **does not square errors**, so outliers have **less influence**.  \n",
        "- It provides a **robust, interpretable** measure of error.  \n",
        "- MSE/RMSE can be **heavily affected** by extreme values.  \n",
        "\n",
        "**Alternative:** If some level of penalization for outliers is acceptable, **Huber loss** (which combines MAE and MSE) can also be considered.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q4. Choosing Between MSE and RMSE for Polynomial Kernel SVM Regression**  \n",
        "If **MSE and RMSE values are close**, **RMSE should be chosen** because:  \n",
        "- It is in the same unit as the target variable (e.g., house price).  \n",
        "- It is more interpretable compared to MSE, which is squared.  \n",
        "- It emphasizes larger errors more than MSE.  \n",
        "\n",
        "Thus, **RMSE is the better metric for performance comparison**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q5. Best Metric for Comparing SVM Regression Models with Different Kernels**  \n",
        "To measure how well the model explains variance, **R-squared (\\(R^2\\))** is the most appropriate metric because:  \n",
        "- It quantifies **how much of the variance in the target variable** is explained by the model.  \n",
        "- It allows for **direct comparison** of different models (linear, polynomial, RBF).  \n",
        "- A higher \\(R^2\\) means a better fit, making it ideal for kernel selection.  \n",
        "\n",
        "Thus, **R-squared (\\(R^2\\)) is the best metric for comparing SVM regression models with different kernels**."
      ],
      "metadata": {
        "id": "kpwImr8RaGr8"
      }
    }
  ]
}